{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Generator\n",
    "from bson.binary import Binary\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "from pymongo.server_api import ServerApi\n",
    "from IPython.display import display, Image\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import tempfile\n",
    "import cv2  # Replacing PIL with a faster library\n",
    "from multiprocessing import Pool  # Importing Pool for multiprocessing\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed  # For multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Environment Variables\n",
    "load_dotenv()\n",
    "username = os.getenv(\"MONGO_USERNAME\")\n",
    "password = os.getenv(\"MONGO_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Username and password for MongoDB Atlas\n",
    "uri = f'mongodb+srv://{username}:{password}@sample-images.qlezbxu.mongodb.net/?retryWrites=true&w=majority'\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a database and a collection within the database\n",
    "db = client['sample-images']\n",
    "embeddings_collection = db['demo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A directory of your images\n",
    "image_directory = \"D:\\AIML\\Scene-Sense\\sample_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq: list, size: int) -> Generator:\n",
    "    \"\"\"Yield chunks of data from a larger list.\"\"\"\n",
    "    if size <= 0:\n",
    "        raise ValueError(\"Size must be a positive integer\")\n",
    "    for pos in range(0, len(seq), size):\n",
    "        yield seq[pos:pos + size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_files(directory: str) -> Generator:\n",
    "    accepted_extensions = [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".webp\"]\n",
    "\n",
    "    # Get list of filenames from directory\n",
    "    filenames = [f for f in os.listdir(directory) if any(f.endswith(ext) for ext in accepted_extensions)]\n",
    "\n",
    "    # Fetch existing image paths from database\n",
    "    image_paths_in_db = set(doc['image_path'] for doc in embeddings_collection.find({}, {'image_path': 1}))\n",
    "\n",
    "    # Using multithreading to speed up the processing of the files\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for filename in filenames:\n",
    "            futures.append(executor.submit(process_image_file, filename, image_paths_in_db, directory))\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_file(filename: str, image_paths_in_db: set, directory: str):\n",
    "    image_path = os.path.join(directory, filename)\n",
    "    if image_path not in image_paths_in_db:\n",
    "        try:\n",
    "            image = cv2.imread(image_path)\n",
    "            resized_image = cv2.resize(image, (224, 224))\n",
    "            temp_file_path = tempfile.mktemp(suffix=\".png\")\n",
    "            cv2.imwrite(temp_file_path, resized_image)\n",
    "            return image_path, temp_file_path\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image '{image_path}': {str(e)}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ThreadPoolExecutor for send_images\n",
    "def send_images(directory: str, batch_size: int = 1000):\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        files_chunks = list(chunker(list(prepare_files(directory)), batch_size))\n",
    "        for chunk_index, files_chunk in enumerate(files_chunks, 1):\n",
    "            futures.append(executor.submit(process_image_chunk, chunk_index, files_chunk, len(files_chunks)))\n",
    "        for future in as_completed(futures):\n",
    "            print(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_chunk(chunk_index, files_chunk, total_chunks):\n",
    "    files = []\n",
    "    file_objects = []  # List to hold file objects\n",
    "    for image_path, temp_file_path in files_chunk:\n",
    "        file_obj = open(temp_file_path, 'rb')  # Store the file object in a variable\n",
    "        file_objects.append(file_obj)  # Add the file object to the list\n",
    "        files.append(('images', (image_path, file_obj, 'image/png')))\n",
    "    print(f\"Processing chunk {chunk_index}/{total_chunks} - {len(files_chunk)} images...\")\n",
    "    response = requests.post('http://148.113.143.16:9999/image_embeddings/', files=files)\n",
    "    if response.status_code == 200:\n",
    "        embeddings = response.json()['image_embeddings']\n",
    "        # Change the documents to include binary image data instead of the image path\n",
    "        documents = [{'image': Binary(open(temp_file_path, 'rb').read()), 'embedding': embedding} \n",
    "                     for (image_path, temp_file_path), embedding in zip(files_chunk, embeddings)]\n",
    "        try:\n",
    "            embeddings_collection.insert_many(documents)\n",
    "            print(f\"Chunk {chunk_index}/{total_chunks} processed successfully!\")\n",
    "        except errors.InvalidDocument as e:\n",
    "            print(f\"Failed to store the images of chunk {chunk_index}/{total_chunks} due to their sizes: {e}\")\n",
    "    else:\n",
    "        print(f'Error while processing chunk {chunk_index}/{total_chunks}: {response.text}')\n",
    "    # Close all open files\n",
    "    for file_obj in file_objects:\n",
    "        file_obj.close()\n",
    "    # Now it's safe to delete the temp files\n",
    "    for _, temp_file_path in files_chunk:\n",
    "        os.remove(temp_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_images(image_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_text(prompt):\n",
    "    data = {\"prompt\": prompt}\n",
    "    response = requests.post('http://148.113.143.16:9999/text_embeddings/', json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f'Error while sending text: {response.text}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_images(text_embedding: str, similarity_threshold: float = 0.22):\n",
    "    # Processing text embeddings\n",
    "    text_embedding = torch.tensor(text_embedding)\n",
    "\n",
    "    # Get all embeddings from the database\n",
    "    documents = embeddings_collection.find()\n",
    "\n",
    "    # Compute similarities with all image embeddings and get all that are above the threshold\n",
    "    similar_images = []\n",
    "    for document in documents:\n",
    "        image_data = document['image']\n",
    "        image_embeddings = torch.tensor(document['embedding'])\n",
    "        similarity = F.cosine_similarity(text_embedding, image_embeddings)\n",
    "        if similarity.item() > similarity_threshold:\n",
    "            similar_images.append((similarity.item(), image_data))\n",
    "\n",
    "    # Sort by similarity score\n",
    "    similar_images = sorted(similar_images, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Return image paths\n",
    "    for sim, img_data in similar_images:\n",
    "        nparr = np.fromstring(img_data, np.uint8)\n",
    "        img_np = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.imshow(cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Similarity: {sim}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_threshold(prompt: str, base_threshold: float = 0.23, increment: float = 0.02) -> float:\n",
    "    words = [word for word in prompt.split() if word not in stop_words]\n",
    "    num_words = len(words)\n",
    "    return base_threshold + num_words * increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a text prompt to the FastAPI server and store the returned embedding\n",
    "prompt = \"car\"\n",
    "text_embedding = send_text(prompt)\n",
    "text_embedding = text_embedding.get('text_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the similarity threshold based on the number of words in the prompt\n",
    "similarity_threshold = compute_similarity_threshold(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get similar images from the database\n",
    "get_similar_images(text_embedding, similarity_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the resource located at the URL\n",
    "# and storing it in the file name a.png\n",
    "url = \"https://prodigalbookable.blob.core.windows.net/prodigalbookable/0013d4c8-5a4d-40a5-98b9-2445a55a4750.png\"\n",
    "urllib.request.urlretrieve(url, \"geeksforgeeks.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
