{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the SQLite database (or create it if it doesn't exist)\n",
    "conn = sqlite3.connect('image_metadata.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image metadata from the database\n",
    "c.execute(\"SELECT file_path, file_name, caption, tags FROM images\")  \n",
    "data = c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the file_paths, file_names, captions, and tags\n",
    "file_paths = [row[0] for row in data]\n",
    "file_names = [row[1] for row in data]\n",
    "captions = [row[2] for row in data]\n",
    "tags = [row[3] for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine captions and tags into a single list of documents\n",
    "documents = [f\"{caption} {tag}\" for caption, tag in zip(captions, tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a TfidfVectorizer and fit it to the documents\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_images(query, threshold=0.05):\n",
    "    # vectorize the query\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    \n",
    "    # calculate cosine similarities between the query and the documents\n",
    "    similarities = cosine_similarity(query_vec, X).flatten()\n",
    "    \n",
    "    # get indices of images above the threshold\n",
    "    above_threshold_indices = [i for i, score in enumerate(similarities) if score > threshold]\n",
    "    \n",
    "    # print out the file paths of the images above the threshold\n",
    "    for index in above_threshold_indices:\n",
    "        print(f\"File name: {file_names[index]}, File path: {file_paths[index]}, Similarity: {similarities[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name: laion2b_en_part_00000_000007.png, File path: D:\\AIML\\gimmick\\Scene-Sense\\test100\\laion2b_en_part_00000_000007.png, Similarity: 0.18630055746048146\n",
      "File name: laion2b_en_part_00000_000438.png, File path: D:\\AIML\\gimmick\\Scene-Sense\\test100\\laion2b_en_part_00000_000438.png, Similarity: 0.1260450349713539\n",
      "File name: laion2b_en_part_00000_000940.png, File path: D:\\AIML\\gimmick\\Scene-Sense\\test100\\laion2b_en_part_00000_000940.png, Similarity: 0.30796071456718993\n",
      "File name: laion2b_en_part_00000_000998.png, File path: D:\\AIML\\gimmick\\Scene-Sense\\test100\\laion2b_en_part_00000_000998.png, Similarity: 0.2462405840188553\n",
      "File name: laion2b_en_part_00001_000036.png, File path: D:\\AIML\\gimmick\\Scene-Sense\\test100\\laion2b_en_part_00001_000036.png, Similarity: 0.22640848782745157\n",
      "File name: laion2b_en_part_00001_000203.png, File path: D:\\AIML\\gimmick\\Scene-Sense\\test100\\laion2b_en_part_00001_000203.png, Similarity: 0.13894008234869507\n",
      "File name: laion2b_en_part_00001_000246.png, File path: D:\\AIML\\gimmick\\Scene-Sense\\test100\\laion2b_en_part_00001_000246.png, Similarity: 0.14212779808913928\n",
      "File name: laion2b_en_part_00001_000280.png, File path: D:\\AIML\\gimmick\\Scene-Sense\\test100\\laion2b_en_part_00001_000280.png, Similarity: 0.29358730495969515\n",
      "File name: laion2b_en_part_00001_000311.png, File path: D:\\AIML\\gimmick\\Scene-Sense\\test100\\laion2b_en_part_00001_000311.png, Similarity: 0.28636135889729947\n",
      "File name: laion2b_en_part_00001_000714.png, File path: D:\\AIML\\gimmick\\Scene-Sense\\test100\\laion2b_en_part_00001_000714.png, Similarity: 0.2941606484228942\n",
      "File name: laion2b_en_part_00001_000771.png, File path: D:\\AIML\\gimmick\\Scene-Sense\\test100\\laion2b_en_part_00001_000771.png, Similarity: 0.2505560947636354\n",
      "File name: laion2b_en_part_00001_000911.png, File path: D:\\AIML\\gimmick\\Scene-Sense\\test100\\laion2b_en_part_00001_000911.png, Similarity: 0.28164652215303015\n"
     ]
    }
   ],
   "source": [
    "# prompt the user to enter a query and run the similarity search\n",
    "query = \"man\"\n",
    "find_similar_images(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
